{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallel computing with Pytorch in deep learning\n",
    "\n",
    "author: Jing Zhang    \n",
    "e-mail: zhangjingnm@hotmail.com    \n",
    "date: 2024-09    \n",
    "reference: http://www.idris.fr/eng/jean-zay/gpu/jean-zay-gpu-torch-multi-eng.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data parallelism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model parallelism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-process configuration with SLURM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Epoch 1/10: Train Loss: 1.1410, Train Acc: 60.10, Test Loss: 0.8326, Test Acc: 71.25%\n",
      "Epoch 2/10: Train Loss: 0.7750, Train Acc: 73.15, Test Loss: 0.7030, Test Acc: 75.96%\n",
      "Epoch 3/10: Train Loss: 0.6593, Train Acc: 76.96, Test Loss: 0.6416, Test Acc: 77.75%\n",
      "Epoch 4/10: Train Loss: 0.5870, Train Acc: 79.59, Test Loss: 0.5958, Test Acc: 79.26%\n",
      "Epoch 5/10: Train Loss: 0.5420, Train Acc: 81.16, Test Loss: 0.5572, Test Acc: 80.90%\n",
      "Epoch 6/10: Train Loss: 0.4965, Train Acc: 82.73, Test Loss: 0.5543, Test Acc: 81.10%\n",
      "Epoch 7/10: Train Loss: 0.4654, Train Acc: 83.87, Test Loss: 0.5373, Test Acc: 81.57%\n",
      "Epoch 8/10: Train Loss: 0.4363, Train Acc: 84.82, Test Loss: 0.5188, Test Acc: 82.19%\n",
      "Epoch 9/10: Train Loss: 0.4177, Train Acc: 85.38, Test Loss: 0.5282, Test Acc: 81.94%\n",
      "Epoch 10/10: Train Loss: 0.3896, Train Acc: 86.30, Test Loss: 0.5135, Test Acc: 82.77%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# data augmentation and preprocessing\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),  \n",
    "    transforms.RandomCrop(32, padding=4),  \n",
    "    transforms.ToTensor(),  \n",
    "    transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.247, 0.243, 0.261]) \n",
    "])\n",
    "\n",
    "# load CIFAR-10 dataset\n",
    "train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=2)\n",
    "\n",
    "# load pretrained ResNet18 model\n",
    "model = models.resnet18(weights='ResNet18_Weights.DEFAULT')\n",
    "\n",
    "# modify last fully connected layer, to adapt for CIFAR-10\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 10)  # 10 classes in CIFAR-10\n",
    "\n",
    "# move model to GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.0001)\n",
    "\n",
    "def train(model, train_loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # backword propagation and optmization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # calculate loss and accuracy\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        _, predicted = outputs.max(1) # get predicted class\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    epoch_acc = 100. * correct / total\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "def evaluate(model, test_loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / len(test_loader.dataset)\n",
    "    epoch_acc = 100. * correct / total\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, train_acc = train(model, train_loader, criterion, optimizer, device)\n",
    "    test_loss, test_acc = evaluate(model, test_loader, criterion, device)\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}: Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}, Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 GPUs in total on this machine\n",
      "GPU 0: Quadro RTX 5000\n",
      "Node name (hostname): DESKTOP-7GS0DEP\n"
     ]
    }
   ],
   "source": [
    "# dell workstation\n",
    "import torch \n",
    "\n",
    "num_gpus = torch.cuda.device_count()\n",
    "print(f'{num_gpus} GPUs in total on this machine')\n",
    "\n",
    "for i in range(num_gpus):\n",
    "    print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "\n",
    "import socket\n",
    "hostname = socket.gethostname()\n",
    "print(f\"Node name (hostname): {hostname}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 GPU in total on this machine\n",
      "GPU 0: NVIDIA GeForce RTX 3050 4GB Laptop GPU\n",
      "Node name (hostname): Lenovo\n",
      "PyTorch version: 2.4.1+cu124\n",
      "CUDA version: 12.4\n"
     ]
    }
   ],
   "source": [
    "# thinkbook\n",
    "import torch \n",
    "\n",
    "num_gpus = torch.cuda.device_count()\n",
    "print(f'{num_gpus} GPU in total on this machine')\n",
    "\n",
    "for i in range(num_gpus):\n",
    "    print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "\n",
    "import socket\n",
    "hostname = socket.gethostname()\n",
    "print(f\"Node name (hostname): {hostname}\")\n",
    "\n",
    "print('PyTorch version:', torch.__version__)  # PyTorch version\n",
    "print('CUDA version:', torch.version.cuda)  # CUDA version"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.6 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d0af3871f74fa798a0a222812f3db7ca3ddb43c51379edde28baf2323a73ac20"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
